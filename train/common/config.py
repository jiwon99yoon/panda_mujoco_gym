#/home/dyros/panda_mujoco_gym/train/common/config.py
"""
í•™ìŠµ ì„¤ì • í´ë˜ìŠ¤
"""

import os
import torch
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Any, Optional


@dataclass
class BaseConfig:
    """ê¸°ë³¸ ì„¤ì • í´ë˜ìŠ¤"""
    # í™˜ê²½ ì„¤ì •
    env_name: str = "FrankaSlideDense-v0"
    algorithm: str = "SAC"
    
    # í•™ìŠµ ì„¤ì •
    total_timesteps: int = 1_000_000
    
    # í™˜ê²½ ê°œì„  ì„¤ì •
    normalize_env: bool = True
    reward_scale: float = 0.1
    
    # í‰ê°€ ì„¤ì • -> ë…¼ë¬¸ì— ë§ê²Œ change, ê¸°ì¡´ eval_freq = 20_000, n_eval_episode = 20
    eval_freq: int = 2_000
    n_eval_episodes: int = 15
    eval_deterministic: bool = True
    
    # ì €ì¥ ì„¤ì •
    save_freq: int = 100_000
    checkpoint_freq: int = 50_000
    
    # ë””ë ‰í† ë¦¬ ì„¤ì • - ìƒëŒ€ ê²½ë¡œ ê¸°ì¤€ : ëª…ë ¹ì´ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ì— ë”°ë¼ í´ë” ìƒì„± ìœ„ì¹˜ê°€ ë‹¬ë¼ì§ 
    #base_dir: str = "outputs" 
    # ë””ë ‰í† ë¦¬ ì„¤ì • - í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ 
    base_dir: str = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
        "outputs"
    )
    # __file__ : í˜„ì¬ íŒŒì¼ì˜ ê²½ë¡œ (ex. /home/dyros/panda_mujoco_gym/trian/common/config.py)
    # os.path.abspath(__file__) : ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    # os.path.dirname: íŒŒì¼ëª… ì œê±° 3ë²ˆ
    experiment_name: Optional[str] = None
    
    # ë‚œìˆ˜ ì‹œë“œ (workerë§ˆë‹¤ seed+rank ë¡œ ë¶„ë¦¬) -> x
    #seed: int = 0
    
    # ë‚œìˆ˜ ì‹œë“œ - ëœë¤ê°’ ì„¤ì •
    seed: Optional[int] = None  #

    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        if self.experiment_name is None:
            self.experiment_name = f"{self.env_name}_{self.algorithm}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # # ì „ì—­ ì‹œë“œ ê³ ì • (numpy, torch, random)
        # import random, numpy as _np, torch as _th
        # random.seed(self.seed)
        # _np.random.seed(self.seed)
        # _th.manual_seed(self.seed)

        # ì‹œë“œê°€ ì§€ì •ëœ ê²½ìš°ì—ë§Œ ê³ ì • (ì£¼ë¡œ ë””ë²„ê¹…/ì¬í˜„ì„±ì„ ìœ„í•´)        
        if self.seed is not None:
            import random
            import numpy as np
            import torch

            random.seed(self.seed)
            np.random.seed(self.seed)
            torch.manual_seed(self.seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(self.seed)
                torch.cuda.manual_seed_all(self.seed)        

            print(f"ğŸ² ì‹œë“œ ê³ ì •: {self.seed}")
        else:
            print("ğŸ² ëœë¤ ì‹œë“œ ì‚¬ìš© (ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ë‹¤ë¥¸ ì´ˆê¸° ìƒíƒœ)")
        # ì‹¤í—˜ë³„ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.exp_dir = os.path.join(self.base_dir, self.experiment_name)
        self.model_dir = os.path.join(self.exp_dir, "models")
        self.log_dir = os.path.join(self.exp_dir, "logs")
        self.checkpoint_dir = os.path.join(self.model_dir, "checkpoints")
        
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        dirs_to_create = [
            self.exp_dir,
            self.model_dir,
            self.log_dir,
            self.checkpoint_dir,
        ]
        
        for dir_path in dirs_to_create:
            os.makedirs(dir_path, exist_ok=True)
            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")


@dataclass
class SACConfig(BaseConfig):
    """SAC ì „ìš© ì„¤ì •"""
    # ë²¡í„° í™˜ê²½ ë³‘ë ¬ ê°œìˆ˜
    n_envs: int = 4
    # (seed ëŠ” BaseConfig ì—ì„œ ìƒì†ë°›ìŠµë‹ˆë‹¤ -> SEEDëŠ” ëœë¤)
        
    ## SAC í•˜ì´í¼íŒŒë¼ë¯¸í„°
    # learning_rate: float = 1e-4
    # buffer_size: int = 1_000_000
    # learning_starts: int = 10_000
    # batch_size: int = 512
    # tau: float = 0.01
    # gamma: float = 0.98
    # train_freq: int = 1
    # gradient_steps: int = 1
    
    ## ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
    # policy_kwargs: Dict[str, Any] = field(default_factory=lambda: {
    #     "net_arch": [256, 256, 128],
    #     "activation_fn": torch.nn.ReLU,
    #     "normalize_images": False
    # })
    # # íƒí—˜ ë…¸ì´ì¦ˆ
    # action_noise_std: float = 0.2
    
    # # ì¶”ê°€ í•™ìŠµ ê¸°ë²•
    # use_sde: bool = True #SDE í™œì„±í™” (ë¹„í™œì„±í™” -> False)
    # sde_sample_freq: int = 4

    # ê¸°ì¡´ SAC í•™ìŠµ í•˜ì´í¼ íŒŒë¼ë¯¸í„° -> ë…¼ë¬¸ ëŒ€ë¡œ Change
    learning_rate: float = 1e-3
    buffer_size: int = 1_000_000
    batch_size: int = 2048
    tau: float = 0.05                   # polyak update tau : polyak(soft) ì—…ë°ì´íŠ¸ ê³„ìˆ˜ê°€ í•´ë‹¹, íƒ€ê¹ƒ ë„¤íŠ¸ì›Œí¬ íŒŒë¼ë¯¸í„°ì—ì„œì˜ tau 
    gamma: float = 0.95                 # discount factor 

    # ì•„ë˜ ê°’ë“¤ì€ ë…¼ë¬¸ì— ì–¸ê¸‰ x -> ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í• ë‹¹ (SB3)
    learning_starts: int = 100       # SACì´ í™˜ê²½ ìƒí˜¸ì‘ìš©ë§Œ í•˜ë©° ê²½í—˜ì„ ëª¨ìœ¼ê¸°ë§Œ í•  íƒ€ì„STEP
    train_freq: int = 1                 # í™˜ê²½ ìŠ¤í… NíšŒ ì§„í–‰í•  ë•Œë§ˆë‹¤ í•™ìŠµì„ ìˆ˜í–‰í•˜ê² ë‹¤ëŠ” ì˜ë¯¸
    gradient_steps: int = 1             # í•™ìŠµí•  ë•Œ Në²ˆì˜ ê²½ì‚¬í•˜ê°• ìŠ¤í…ì„ ë°Ÿì„ì§€ ê²°ì • 
    
    # ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° change -> ë…¼ë¬¸
    policy_kwargs: Dict[str, Any] = field(default_factory=lambda: {
        "net_arch": [512, 512, 512],
        "activation_fn": torch.nn.ReLU,
        "normalize_images": False
    })

    # íƒí—˜ ë…¸ì´ì¦ˆ
    action_noise_std: float = 0.2
    
    # ì¶”ê°€ í•™ìŠµ ê¸°ë²•
    use_sde: bool = True #SDE í™œì„±í™” (ë¹„í™œì„±í™” -> False)
    sde_sample_freq: int = 4
    
    # í•™ìŠµ ë‹¨ê³„ ì •ì˜ (ë¹„ë””ì˜¤ ë…¹í™”ìš©)
    stages: Dict[str, float] = field(default_factory=lambda: {
        '0_random': 0,
        '1_20percent': 0.2,
        '2_40percent': 0.4,
        '3_60percent': 0.6,
        '4_80percent': 0.8,
        '5_100percent': 1.0
    })
    
    def get_stage_timesteps(self) -> Dict[str, int]:
        """ê° ë‹¨ê³„ë³„ íƒ€ì„ìŠ¤í… ê³„ì‚°"""
        return {name: int(ratio * self.total_timesteps) 
                for name, ratio in self.stages.items()}
