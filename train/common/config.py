#/home/dyros/panda_mujoco_gym/train/common/config.py
"""
í•™ìŠµ ì„¤ì • í´ë˜ìŠ¤
"""

import os
import torch
from datetime import datetime
from dataclasses import dataclass, field
from typing import Dict, Any, Optional


@dataclass
class BaseConfig:
    """ê¸°ë³¸ ì„¤ì • í´ë˜ìŠ¤"""
    # í™˜ê²½ ì„¤ì •
    env_name: str = "FrankaSlideDense-v0"
    algorithm: str = "SAC"
    
    # í•™ìŠµ ì„¤ì •
    total_timesteps: int = 1_000_000
    
    # í™˜ê²½ ê°œì„  ì„¤ì •
    normalize_env: bool = True
    reward_scale: float = 0.1
    
    # í‰ê°€ ì„¤ì •
    eval_freq: int = 20_000
    n_eval_episodes: int = 20
    eval_deterministic: bool = True
    
    # ì €ì¥ ì„¤ì •
    save_freq: int = 100_000
    checkpoint_freq: int = 50_000
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    base_dir: str = "outputs"
    experiment_name: Optional[str] = None
    
    # ë‚œìˆ˜ ì‹œë“œ (workerë§ˆë‹¤ seed+rank ë¡œ ë¶„ë¦¬)
    seed: int = 0
    
    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì²˜ë¦¬"""
        if self.experiment_name is None:
            self.experiment_name = f"{self.env_name}_{self.algorithm}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # ì „ì—­ ì‹œë“œ ê³ ì • (numpy, torch, random)
        import random, numpy as _np, torch as _th
        random.seed(self.seed)
        _np.random.seed(self.seed)
        _th.manual_seed(self.seed)
        
        # ì‹¤í—˜ë³„ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.exp_dir = os.path.join(self.base_dir, self.experiment_name)
        self.model_dir = os.path.join(self.exp_dir, "models")
        self.log_dir = os.path.join(self.exp_dir, "logs")
        self.checkpoint_dir = os.path.join(self.model_dir, "checkpoints")
        
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        dirs_to_create = [
            self.exp_dir,
            self.model_dir,
            self.log_dir,
            self.checkpoint_dir,
        ]
        
        for dir_path in dirs_to_create:
            os.makedirs(dir_path, exist_ok=True)
            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")


@dataclass
class SACConfig(BaseConfig):
    """SAC ì „ìš© ì„¤ì •"""
    # ë²¡í„° í™˜ê²½ ë³‘ë ¬ ê°œìˆ˜
    n_envs: int = 4
    # (seed ëŠ” BaseConfig ì—ì„œ ìƒì†ë°›ìŠµë‹ˆë‹¤)
        
    # SAC í•˜ì´í¼íŒŒë¼ë¯¸í„°
    learning_rate: float = 1e-4
    buffer_size: int = 1_000_000
    learning_starts: int = 10_000
    batch_size: int = 512
    tau: float = 0.01
    gamma: float = 0.98
    train_freq: int = 4
    gradient_steps: int = 4
    
    # ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°
    policy_kwargs: Dict[str, Any] = field(default_factory=lambda: {
        "net_arch": [256, 256, 128],
        "activation_fn": torch.nn.ReLU,
        "normalize_images": False
    })
    
    # íƒí—˜ ë…¸ì´ì¦ˆ
    action_noise_std: float = 0.2
    
    # ì¶”ê°€ í•™ìŠµ ê¸°ë²•
    use_sde: bool = False #SDE ë¹„í™œì„±í™”
    sde_sample_freq: int = 4
    
    # í•™ìŠµ ë‹¨ê³„ ì •ì˜ (ë¹„ë””ì˜¤ ë…¹í™”ìš©)
    stages: Dict[str, float] = field(default_factory=lambda: {
        '0_random': 0,
        '1_20percent': 0.2,
        '2_40percent': 0.4,
        '3_60percent': 0.6,
        '4_80percent': 0.8,
        '5_100percent': 1.0
    })
    
    def get_stage_timesteps(self) -> Dict[str, int]:
        """ê° ë‹¨ê³„ë³„ íƒ€ì„ìŠ¤í… ê³„ì‚°"""
        return {name: int(ratio * self.total_timesteps) 
                for name, ratio in self.stages.items()}
