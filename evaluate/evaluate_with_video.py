#/home/dyros/panda_mujoco_gym/evaluate/evaluate_with_video.py
#!/usr/bin/env python3
"""
ëª¨ë¸ í‰ê°€ ë° ë¹„ë””ì˜¤ ìƒì„± í†µí•© ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import argparse
import numpy as np
from typing import Dict, List, Optional
from stable_baselines3.common.evaluation import evaluate_policy

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

# ì‚¬ìš©ì ì •ì˜ í™˜ê²½ ë“±ë¡
import panda_mujoco_gym

# Utils ì„í¬íŠ¸
from utils import (
    load_model, load_json, save_json, get_experiment_info,
    find_latest_experiment, create_vec_env
)

# Evaluate ëª¨ë“ˆ ì„í¬íŠ¸
from video_recorder import StageVideoRecorder


def evaluate_model_performance(model, env, num_episodes: int = 50) -> Dict:
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘... ({num_episodes}ê°œ ì—í”¼ì†Œë“œ)")
    
    # evaluate_policyë¡œ ê¸°ë³¸ í‰ê°€
    rewards, lengths = evaluate_policy(
        model, env,
        n_eval_episodes=num_episodes,
        deterministic=True,
        return_episode_rewards=True
    )
    
    # ì„±ê³µë¥  ê³„ì‚°ì„ ìœ„í•œ ì¶”ê°€ í‰ê°€
    success_count = 0
    for i in range(num_episodes):
        obs = env.reset()
        done = False
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, dones, infos = env.step(action)
            done = dones[0]
            if done and infos[0].get('is_success', False):
                success_count += 1
                break
    
    results = {
        'mean_reward': float(np.mean(rewards)),
        'std_reward': float(np.std(rewards)),
        'min_reward': float(np.min(rewards)),
        'max_reward': float(np.max(rewards)),
        'mean_length': float(np.mean(lengths)),
        'success_rate': success_count / num_episodes,
        'num_episodes': num_episodes,
        'all_rewards': [float(r) for r in rewards],
        'all_lengths': [int(l) for l in lengths]
    }
    
    print(f"   í‰ê·  ë³´ìƒ: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
    print(f"   ì„±ê³µë¥ : {results['success_rate']:.3f}")
    print(f"   í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´: {results['mean_length']:.1f}")
    
    return results


def evaluate_experiment(exp_dir: str, 
                       stages: List[str] = None,
                       num_eval_episodes: int = 50,
                       num_video_episodes: int = 3,
                       record_video: bool = True,
                       create_highlights: bool = True) -> Dict:
    """
    ì‹¤í—˜ ê²°ê³¼ í‰ê°€ ë° ë¹„ë””ì˜¤ ìƒì„±
    
    Args:
        exp_dir: ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        stages: í‰ê°€í•  ë‹¨ê³„ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ë‹¨ê³„)
        num_eval_episodes: ì„±ëŠ¥ í‰ê°€ìš© ì—í”¼ì†Œë“œ ìˆ˜
        num_video_episodes: ê° ë‹¨ê³„ë³„ ë¹„ë””ì˜¤ ì—í”¼ì†Œë“œ ìˆ˜
        record_video: ë¹„ë””ì˜¤ ë…¹í™” ì—¬ë¶€
        create_highlights: í•˜ì´ë¼ì´íŠ¸ ìƒì„± ì—¬ë¶€
    
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("=" * 60)
    print(f"ğŸ” ì‹¤í—˜ í‰ê°€ ì‹œì‘")
    print(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {exp_dir}")
    print("=" * 60)
    
    # ì‹¤í—˜ ì •ë³´ ë¡œë“œ
    exp_info = get_experiment_info(exp_dir)
    if not exp_info:
        raise ValueError(f"ì‹¤í—˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exp_dir}")
    
    env_name = exp_info.get('env_name', 'FrankaSlideDense-v0')
    algorithm = exp_info.get('algorithm', 'SAC')
    reward_scale = exp_info.get('config', {}).get('reward_scale', 0.1)
    
    print(f"\nğŸ“‹ ì‹¤í—˜ ì •ë³´:")
    print(f"   í™˜ê²½: {env_name}")
    print(f"   ì•Œê³ ë¦¬ì¦˜: {algorithm}")
    print(f"   ë³´ìƒ ìŠ¤ì¼€ì¼: {reward_scale}")
    print(f"   ì´ í•™ìŠµ ìŠ¤í…: {exp_info.get('total_timesteps', 'Unknown')}")
    
    # í‰ê°€í•  ëª¨ë¸ ì°¾ê¸°
    models_dir = os.path.join(exp_dir, 'models')
    available_models = exp_info.get('available_models', [])
    
    if not available_models:
        raise ValueError(f"ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {models_dir}")
    
    # í‰ê°€í•  stage ëª¨ë¸ ì„ íƒ
    if stages is None or 'all' in stages:
        stage_models = [m for m in available_models if m.startswith('stage_')]
        stage_models.sort()
    else:
        stage_models = []
        for stage in stages:
            model_name = f'stage_{stage}'
            if model_name in available_models:
                stage_models.append(model_name)
    
    # final ëª¨ë¸ì´ ìˆìœ¼ë©´ ì¶”ê°€
    if 'final_model' in available_models and (stages is None or 'final' in stages or 'all' in stages):
        stage_models.append('final_model')
    
    print(f"\nğŸ“¦ í‰ê°€í•  ëª¨ë¸ ({len(stage_models)}ê°œ):")
    for model in stage_models:
        print(f"   - {model}")
    
    # í™˜ê²½ ìƒì„±
    vec_normalize_path = os.path.join(models_dir, 'vec_normalize.pkl')
    eval_env = create_vec_env(
        env_name,
        n_envs=1,
        normalize=True,
        reward_scale=reward_scale,
        vec_normalize_path=vec_normalize_path if os.path.exists(vec_normalize_path) else None,
        training=False,
        render_mode=None
    )
    
    # í‰ê°€ ë””ë ‰í† ë¦¬ ìƒì„±
    evaluation_dir = os.path.join(exp_dir, 'evaluation')
    os.makedirs(evaluation_dir, exist_ok=True)
    
    # ë¹„ë””ì˜¤ ë…¹í™” ì¤€ë¹„
    if record_video:
        videos_dir = os.path.join(evaluation_dir, 'videos')
        video_recorder = StageVideoRecorder(videos_dir)
    
    # í‰ê°€ ê²°ê³¼ ì €ì¥
    all_results = {
        'experiment_info': exp_info,
        'evaluation_config': {
            'num_eval_episodes': num_eval_episodes,
            'num_video_episodes': num_video_episodes,
            'stages_evaluated': stage_models
        },
        'model_performances': {},
        'video_recordings': {}
    }
    
    # ê° ëª¨ë¸ í‰ê°€
    for model_name in stage_models:
        print(f"\n{'='*50}")
        print(f"ğŸ¯ í‰ê°€ ì¤‘: {model_name}")
        print(f"{'='*50}")
        
        model_path = os.path.join(models_dir, f"{model_name}.zip")
        
        # ëª¨ë¸ ë¡œë“œ
        if model_name == 'stage_0_random':
            # Random policyëŠ” ëª¨ë¸ ì—†ì´ ì§„í–‰
            model = None
            print("   ğŸ² Random Policy ì‚¬ìš©")
        else:
            model = load_model(model_path, algorithm=algorithm, env=eval_env)
            print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ì„±ëŠ¥ í‰ê°€ (random policy ì œì™¸)
        if model is not None:
            performance = evaluate_model_performance(model, eval_env, num_eval_episodes)
            all_results['model_performances'][model_name] = performance
        else:
            print("   â­ï¸  Random PolicyëŠ” ì„±ëŠ¥ í‰ê°€ ìƒëµ")
            all_results['model_performances'][model_name] = {
                'note': 'Random policy - performance evaluation skipped'
            }
        
        # ë¹„ë””ì˜¤ ë…¹í™”
        if record_video:
            # ë¹„ë””ì˜¤ìš© í™˜ê²½ ìƒì„± (ë Œë”ë§ í™œì„±í™”)
            video_env = create_vec_env(
                env_name,
                n_envs=1,
                normalize=True,
                reward_scale=reward_scale,
                vec_normalize_path=vec_normalize_path if os.path.exists(vec_normalize_path) else None,
                training=False,
                render_mode='rgb_array'

            )
            # ë Œë” ëª¨ë“œ ì„¤ì •
            #video_env.env_method('set_render_mode', 'rgb_array')
            
            # stage ì´ë¦„ ì¶”ì¶œ
            if model_name.startswith('stage_'):
                stage_name = model_name.replace('stage_', '')
            else:
                stage_name = model_name
            
            # ì—í”¼ì†Œë“œ ë…¹í™”
            video_results = video_recorder.record_stage_episodes(
                stage_name, model, video_env, num_video_episodes
            )
            
            all_results['video_recordings'][model_name] = {
                'num_videos': len(video_results),
                'episodes': video_results
            }
    
    # í•˜ì´ë¼ì´íŠ¸ ìƒì„±
    if record_video and create_highlights:
        video_recorder.create_highlight_reel()
    
    # í‰ê°€ ìš”ì•½ ì €ì¥
    if record_video:
        video_summary = video_recorder.save_evaluation_summary()
        all_results['video_summary'] = video_summary
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    results_path = os.path.join(evaluation_dir, 'evaluation_results.json')
    save_json(all_results, results_path)
    
    print("\n" + "=" * 60)
    print("âœ… í‰ê°€ ì™„ë£Œ!")
    print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {results_path}")
    if record_video:
        print(f"ğŸ¥ ë¹„ë””ì˜¤ ì €ì¥: {os.path.join(evaluation_dir, 'videos')}")
    print("=" * 60)
    
    return all_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ëª¨ë¸ í‰ê°€ ë° ë¹„ë””ì˜¤ ìƒì„±")
    
    # ì‹¤í—˜ ì„ íƒ
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--exp-dir", type=str, help="ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    group.add_argument("--latest", action="store_true", help="ê°€ì¥ ìµœê·¼ ì‹¤í—˜ í‰ê°€")
    
    # í‰ê°€ ì˜µì…˜
    parser.add_argument("--stages", type=str, nargs='+', default=None,
                       help="í‰ê°€í•  ë‹¨ê³„ (ì˜ˆ: 0_random 1_20percent final) ë˜ëŠ” 'all'")
    parser.add_argument("--num-eval", type=int, default=50,
                       help="ì„±ëŠ¥ í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸: 50)")
    parser.add_argument("--num-video", type=int, default=3,
                       help="ê° ë‹¨ê³„ë³„ ë¹„ë””ì˜¤ ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸: 3)")
    parser.add_argument("--no-video", action="store_true",
                       help="ë¹„ë””ì˜¤ ë…¹í™” ë¹„í™œì„±í™”")
    parser.add_argument("--no-highlights", action="store_true",
                       help="í•˜ì´ë¼ì´íŠ¸ ìƒì„± ë¹„í™œì„±í™”")
    
    args = parser.parse_args()
    
    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²°ì •
    if args.latest:
        exp_dir = find_latest_experiment()
        if exp_dir is None:
            print("âŒ ìµœê·¼ ì‹¤í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        print(f"ğŸ“ ìµœì‹  ì‹¤í—˜ ë°œê²¬: {exp_dir}")
    else:
        exp_dir = args.exp_dir
        if not os.path.exists(exp_dir):
            print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exp_dir}")
            return
    
    # í‰ê°€ ì‹¤í–‰
    try:
        results = evaluate_experiment(
            exp_dir=exp_dir,
            stages=args.stages,
            num_eval_episodes=args.num_eval,
            num_video_episodes=args.num_video,
            record_video=not args.no_video,
            create_highlights=not args.no_highlights
        )
        
        # ê°„ë‹¨í•œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\nğŸ“ˆ í‰ê°€ ê²°ê³¼ ìš”ì•½:")
        for model_name, perf in results['model_performances'].items():
            if 'mean_reward' in perf:
                print(f"   {model_name}: ë³´ìƒ {perf['mean_reward']:.2f} Â± {perf['std_reward']:.2f}, "
                      f"ì„±ê³µë¥  {perf['success_rate']:.3f}")
        
    except Exception as e:
        print(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
